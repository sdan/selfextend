{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../../../../ && python -m pip install -e .\n",
    "from transformers.models.mistral import MistralForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "model = MistralForCausalLM.from_pretrained(\"hf_mistral-7B-v0.1\", attn_implementation=\"self_extend\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hf_mistral-7B-v0.1\")\n",
    "\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens encoding\n",
    "prompt = \"What is the fastest ever military jet that has been used in military operations.\"\n",
    "model_inputs = tokenizer([prompt], return_tensors='pt').to(device)\n",
    "model.to(device)\n",
    "\n",
    "# Generate sequence\n",
    "generated_tokens = model.generate(**model_inputs, max_new_tokens=100) \n",
    "\n",
    "# Decode generated sequence\n",
    "generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
